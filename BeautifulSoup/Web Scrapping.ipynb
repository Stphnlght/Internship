{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8e5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary libraries\n",
    "import pandas as pd\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d641e",
   "metadata": {},
   "source": [
    "## 1) wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2ef75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_scrap(link):\n",
    "    \n",
    "    # scrapping data from webpage with BeautifulSoup\n",
    "    url = requests.get(link)\n",
    "    soup = BeautifulSoup(url.text, 'html.parser')\n",
    "    story = soup.find_all(['h1', 'h2','h3'])\n",
    "    \n",
    "    # printing the data\n",
    "    for i in story:\n",
    "        print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b36fb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page\n",
      "Welcome to Wikipedia\n",
      "From today's featured article\n",
      "Did you know ...\n",
      "In the news\n",
      "On this day\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n",
      "Navigation menu\n",
      "\n",
      "Personal tools\n",
      "\n",
      "\n",
      "Namespaces\n",
      "\n",
      "\n",
      "Views\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "Navigation\n",
      "\n",
      "\n",
      "Contribute\n",
      "\n",
      "\n",
      "Tools\n",
      "\n",
      "\n",
      "Print/export\n",
      "\n",
      "\n",
      "In other projects\n",
      "\n",
      "\n",
      "Languages\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wiki_scrap('https://en.wikipedia.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12079f68",
   "metadata": {},
   "source": [
    "## 2) IMDB’s Top Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efcf7e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_movies(link):\n",
    "    # initializing the lists\n",
    "    titles = []\n",
    "    years = []\n",
    "    ratings = []\n",
    "    \n",
    "    # extracting data from webpage with BeautifulSoup\n",
    "    url = requests.get(link)\n",
    "    soup = BeautifulSoup(url.text, 'html.parser')\n",
    "    top_100 = soup.find_all('td',class_=\"titleColumn\", limit=100)\n",
    "    \n",
    "    # appending the data to various lists\n",
    "    for i in top_100:\n",
    "        titles_extract = i.find_all('a')\n",
    "        titles.append([i.text for i in titles_extract])\n",
    "    for x in soup.find_all('span', class_=\"secondaryInfo\", limit=100):\n",
    "        years.append(x.text[1:-1])\n",
    "    for y in soup.find_all('td', class_=\"ratingColumn imdbRating\", limit=100):\n",
    "        ratings.append(y.text.strip())\n",
    "        \n",
    "    # imputing the data into a data frame\n",
    "    df = pd.DataFrame({'Titles':titles, 'Year':years, 'Rating':ratings})\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1cbfda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The Shawshank Redemption]</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The Godfather]</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The Dark Knight]</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The Godfather: Part II]</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[12 Angry Men]</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Citizen Kane]</td>\n",
       "      <td>1941</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[M]</td>\n",
       "      <td>1931</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[North by Northwest]</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[Idi i smotri]</td>\n",
       "      <td>1985</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[Vertigo]</td>\n",
       "      <td>1958</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Titles  Year Rating\n",
       "1    [The Shawshank Redemption]  1994    9.2\n",
       "2               [The Godfather]  1972    9.2\n",
       "3             [The Dark Knight]  2008    9.0\n",
       "4      [The Godfather: Part II]  1974    9.0\n",
       "5                [12 Angry Men]  1957    8.9\n",
       "..                          ...   ...    ...\n",
       "96               [Citizen Kane]  1941    8.3\n",
       "97                          [M]  1931    8.3\n",
       "98         [North by Northwest]  1959    8.3\n",
       "99               [Idi i smotri]  1985    8.2\n",
       "100                   [Vertigo]  1958    8.2\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_movies('https://www.imdb.com/chart/top/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a139a",
   "metadata": {},
   "source": [
    "## 3) Top Indian Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea364c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_indian(link):\n",
    "    \n",
    "    # initializing vaarious lists\n",
    "    titles = []\n",
    "    years = []\n",
    "    ratings = []\n",
    "    \n",
    "    # extracting data from webpage with BeautifulSoup\n",
    "    url = requests.get(link)\n",
    "    soup = BeautifulSoup(url.text, 'html.parser')\n",
    "    top_100 = soup.find_all('td',class_=\"titleColumn\", limit=100)\n",
    "    \n",
    "    # appending the data to various lists\n",
    "    for i in top_100:\n",
    "        titles_extract = i.find_all('a')\n",
    "        titles.append([i.text for i in titles_extract])\n",
    "    for x in soup.find_all('span', class_=\"secondaryInfo\", limit=100):\n",
    "        years.append(x.text[1:-1])\n",
    "    for y in soup.find_all('td', class_=\"ratingColumn imdbRating\", limit=100):\n",
    "        ratings.append(y.text.strip())\n",
    "        \n",
    "    # imputing the data into a data frame\n",
    "    df = pd.DataFrame({'Titles':titles, 'Year':years, 'Rating':ratings})\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2285af76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Rocketry: The Nambi Effect]</td>\n",
       "      <td>2022</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Anbe Sivam]</td>\n",
       "      <td>2003</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Jai Bhim]</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Nayakan]</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Golmaal]</td>\n",
       "      <td>1979</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Ustad Hotel]</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[The Legend of Bhagat Singh]</td>\n",
       "      <td>2002</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[Virumandi]</td>\n",
       "      <td>2004</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[Baahubali 2: The Conclusion]</td>\n",
       "      <td>2017</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[Angoor]</td>\n",
       "      <td>1982</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Titles  Year Rating\n",
       "1     [Rocketry: The Nambi Effect]  2022    8.5\n",
       "2                     [Anbe Sivam]  2003    8.4\n",
       "3                       [Jai Bhim]  2021    8.4\n",
       "4                        [Nayakan]  1987    8.4\n",
       "5                        [Golmaal]  1979    8.4\n",
       "..                             ...   ...    ...\n",
       "96                   [Ustad Hotel]  2012    8.0\n",
       "97    [The Legend of Bhagat Singh]  2002    8.0\n",
       "98                     [Virumandi]  2004    8.0\n",
       "99   [Baahubali 2: The Conclusion]  2017    8.0\n",
       "100                       [Angoor]  1982    8.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_indian('https://www.imdb.com/india/top-rated-indian-movies/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dffe0f8",
   "metadata": {},
   "source": [
    "## 4) Presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a6d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def former_presidents(link):\n",
    "    \n",
    "    # initializing various lists\n",
    "    names = []\n",
    "    service_term = []\n",
    "    url = requests.get(link)\n",
    "    \n",
    "    # extracting data from webpage with BeautifulSoup\n",
    "    content = BeautifulSoup(url.text, 'html.parser')\n",
    "    names_extract = content.find_all('h3')\n",
    "    serv_term = content.find('ul', class_='listing cf')\n",
    "    links = serv_term.find_all('a')\n",
    "    \n",
    "    # appending the data to various lists\n",
    "    for i in links:\n",
    "        i.extract()\n",
    "    spans = serv_term.find_all('span')\n",
    "    for x in spans:\n",
    "        x.extract()\n",
    "    for terms in serv_term.find_all('p'):\n",
    "        service_term.append(terms.text)\n",
    "    for name in names_extract:\n",
    "        names.append(name.text)\n",
    "    for ele in service_term:\n",
    "        if ele == '':\n",
    "            service_term.remove(ele)\n",
    "            \n",
    "    # imputing the data into a data frame\n",
    "    df = pd.DataFrame({'Names': names, 'Service Term': service_term})\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b10b5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Service Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Names  \\\n",
       "1           Shri Ram Nath Kovind (birth - 1945)   \n",
       "2             Shri Pranab Mukherjee (1935-2020)   \n",
       "3   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "4            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "5            Shri K. R. Narayanan (1920 - 2005)   \n",
       "6           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "7               Shri R Venkataraman (1910-2009)   \n",
       "8                  Giani Zail Singh (1916-1994)   \n",
       "9         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "10         Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "11     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "12                 Dr. Zakir Husain (1897-1969)   \n",
       "13     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "14             Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                         Service Term  \n",
       "1                     25 July, 2017 to 25 July, 2022   \n",
       "2                     25 July, 2012 to 25 July, 2017   \n",
       "3                     25 July, 2007 to 25 July, 2012   \n",
       "4                     25 July, 2002 to 25 July, 2007   \n",
       "5                     25 July, 1997 to 25 July, 2002   \n",
       "6                     25 July, 1992 to 25 July, 1997   \n",
       "7                     25 July, 1987 to 25 July, 1992   \n",
       "8                     25 July, 1982 to 25 July, 1987   \n",
       "9                     25 July, 1977 to 25 July, 1982   \n",
       "10               24 August, 1974 to 11 February, 1977  \n",
       "11   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "12                        13 May, 1967 to 3 May, 1969  \n",
       "13                       13 May, 1962 to 13 May, 1967  \n",
       "14                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "former_presidents('https://presidentofindia.nic.in/former-presidents.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945065b0",
   "metadata": {},
   "source": [
    "## 5) ICC Men Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c7fd0",
   "metadata": {},
   "source": [
    "### A) Top 10 ODI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa79d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def men_ranking(link1):\n",
    "    \n",
    "    # intializing various lists\n",
    "    teams = []\n",
    "    matches = []\n",
    "    points =[]\n",
    "    ratings = []\n",
    "    \n",
    "    # extracting data from webpage with BeautifulSoup\n",
    "    url = requests.get(link1)\n",
    "    content = BeautifulSoup(url.text, 'html.parser')\n",
    "    team = content.find_all('span', class_='u-hide-phablet') \n",
    "    match = content.find_all('td', class_='rankings-block__banner--matches') + content.find_all('td', class_='table-body__cell u-center-text')\n",
    "    point = content.find_all('td', class_='rankings-block__banner--points') + content.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "    rating = content.find_all('td', class_='rankings-block__banner--rating u-text-right') + content.find_all('td', class_='table-body__cell u-text-right rating')\n",
    "    \n",
    "    # appending the data to various lists\n",
    "    for a in point:\n",
    "        if len(a.text.strip()) >= 3:\n",
    "            points.append(a.text)\n",
    "    for a in match:\n",
    "        if len(a.text.strip()) < 3:\n",
    "            matches.append(a.text)\n",
    "    for a in team:\n",
    "        teams.append(a.text.strip())\n",
    "    for a in rating:\n",
    "        ratings.append(a.text.strip())\n",
    "        \n",
    "     # imputing the data into a data frame   \n",
    "    df = pd.DataFrame({'Teams':teams, 'Matches':matches, 'Points':points, 'Ratings':ratings})\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9460045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>19</td>\n",
       "      <td>2,439</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>3,318</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>25</td>\n",
       "      <td>2,606</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>England</td>\n",
       "      <td>43</td>\n",
       "      <td>4,449</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>27</td>\n",
       "      <td>2,704</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>23</td>\n",
       "      <td>2,111</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>23</td>\n",
       "      <td>1,916</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>25</td>\n",
       "      <td>1,988</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>22</td>\n",
       "      <td>1,047</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Teams Matches Points Ratings\n",
       "1      Australia      19  2,439     128\n",
       "2          India      29  3,318     114\n",
       "3   South Africa      25  2,606     104\n",
       "4        England      43  4,449     103\n",
       "5    New Zealand      27  2,704     100\n",
       "6       Pakistan      23  2,111      92\n",
       "7      Sri Lanka      23  1,916      83\n",
       "8    West Indies      25  1,988      80\n",
       "9     Bangladesh      22  1,047      48\n",
       "10      Zimbabwe       6    148      25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "men_ranking('https://www.icc-cricket.com/rankings/mens/team-rankings/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db7fa0",
   "metadata": {},
   "source": [
    "### B) Top 10 Batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "018ed520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batsmen(link):\n",
    "    \n",
    "    # intializing various lists\n",
    "    players = []\n",
    "    teams1 = []\n",
    "    ratings1 = []\n",
    "    \n",
    "    # extracting data from webpage with BeautifulSoup\n",
    "    url = requests.get(link)\n",
    "    content = BeautifulSoup(url.text, 'html.parser') \n",
    "    player = content.find_all('div',class_=\"rankings-block__banner--name-large\") + content.find_all('td', class_=\"table-body__cell rankings-table__name name\", limit=9)\n",
    "    team = content.find_all('div', class_=\"rankings-block__banner--nationality\") + content.find_all('span', class_=\"table-body__logo-text\", limit=9)\n",
    "    rating = content.find_all('div', class_=\"rankings-block__banner--rating\") + content.find_all('td', class_=\"table-body__cell rating\", limit=9)\n",
    "    \n",
    "    # appending the data to various lists\n",
    "    for a in rating:\n",
    "        ratings1.append(a.text.strip())\n",
    "    for a in player:\n",
    "        players.append(a.text.strip())\n",
    "    for a in team:\n",
    "        teams1.append(a.text[0:5].strip())\n",
    "        \n",
    "    # imputing the data into a data frame\n",
    "    df = pd.DataFrame({'Players': players, 'Teams': teams1, 'Ratings': ratings1})\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5253696a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Players</th>\n",
       "      <th>Teams</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Players Teams Ratings\n",
       "1              Babar Azam   PAK     890\n",
       "2   Rassie van der Dussen    SA     789\n",
       "3         Quinton de Kock    SA     784\n",
       "4             Imam-ul-Haq   PAK     779\n",
       "5             Virat Kohli   IND     744\n",
       "6            Rohit Sharma   IND     740\n",
       "7          Jonny Bairstow   ENG     732\n",
       "8            David Warner   AUS     725\n",
       "9             Ross Taylor    NZ     701\n",
       "10            Steve Smith   AUS     697"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batsmen('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a8b88",
   "metadata": {},
   "source": [
    "### C) Top 10 Bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c530d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bowlers(link):\n",
    "    \n",
    "    # intializing various lists\n",
    "    players2 = []\n",
    "    teams2 = []\n",
    "    ratings2 = []\n",
    "    \n",
    "    # extracting data from webpage with BeautifulSoup\n",
    "    url = requests.get(link)\n",
    "    content3 = BeautifulSoup(url.text, 'html.parser') \n",
    "    player = content3.find_all('div',class_=\"rankings-block__banner--name-large\") + content3.find_all('td', class_=\"table-body__cell rankings-table__name name\", limit=9)\n",
    "    team = content3.find_all('div', class_=\"rankings-block__banner--nationality\") + content3.find_all('span', class_=\"table-body__logo-text\", limit=9)\n",
    "    rating = content3.find_all('div', class_=\"rankings-block__banner--rating\") + content3.find_all('td', class_=\"table-body__cell rating\", limit=9)\n",
    "    \n",
    "    # appending the data to various lists\n",
    "    for a in rating:\n",
    "        ratings2.append(a.text.strip())\n",
    "    for a in player:\n",
    "        players2.append(a.text.strip())\n",
    "    for a in team:\n",
    "        teams2.append(a.text[0:5].strip())\n",
    "        \n",
    "    # imputing the data into a data frame\n",
    "    df = pd.DataFrame({'Players': players2, 'Teams': teams2, 'Ratings': ratings2})\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37e76f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Players</th>\n",
       "      <th>Teams</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Players Teams Ratings\n",
       "1        Trent Boult    NZ     775\n",
       "2     Josh Hazlewood   AUS     718\n",
       "3   Mujeeb Ur Rahman   AFG     676\n",
       "4     Jasprit Bumrah   IND     662\n",
       "5     Shaheen Afridi   PAK     661\n",
       "6      Mohammad Nabi   AFG     657\n",
       "7       Mehedi Hasan   BAN     655\n",
       "8         Matt Henry    NZ     654\n",
       "9     Mitchell Starc   AUS     653\n",
       "10       Rashid Khan   AFG     651"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowlers('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104afe01",
   "metadata": {},
   "source": [
    "\n",
    "## 6) ICC Women Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81791c32",
   "metadata": {},
   "source": [
    "### A) Top 10 ODI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9f0680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def women_ranking(link1):\n",
    "    \n",
    "    # intializing various lists\n",
    "    teams_w = []\n",
    "    matches_w = []\n",
    "    points_w =[]\n",
    "    ratings_w = []\n",
    "    \n",
    "    # extracting data from webpage with BeautifulSoup\n",
    "    url = requests.get(link1)\n",
    "    content = BeautifulSoup(url.text, 'html.parser')\n",
    "    team = content.find_all('span', class_='u-hide-phablet',limit=10) \n",
    "    match = content.find_all('td', class_='rankings-block__banner--matches') + content.find_all('td', class_='table-body__cell u-center-text')\n",
    "    point = content.find_all('td', class_='rankings-block__banner--points') + content.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "    rating = content.find_all('td', class_='rankings-block__banner--rating u-text-right') + content.find_all('td', class_='table-body__cell u-text-right rating',limit=9)\n",
    "    \n",
    "    # appending the data to various lists\n",
    "    for a in point:\n",
    "        if len(a.text.strip()) >= 3:\n",
    "            points_w.append(a.text)\n",
    "    for a in match:\n",
    "        if len(a.text.strip()) < 3:\n",
    "            matches_w.append(a.text)\n",
    "    for a in team:\n",
    "        teams_w.append(a.text.strip())\n",
    "    for a in rating:\n",
    "        ratings_w.append(a.text.strip())\n",
    "        \n",
    "    # imputing the data into a data frame\n",
    "    df = pd.DataFrame({'Teams':teams_w, 'Matches':matches_w[0:10], 'Points':points_w, 'Ratings':ratings_w})\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4689e623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>4,837</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>36</td>\n",
       "      <td>4,205</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>35</td>\n",
       "      <td>3,732</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>33</td>\n",
       "      <td>3,302</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>32</td>\n",
       "      <td>2,864</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>930</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>30</td>\n",
       "      <td>1,962</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>11</td>\n",
       "      <td>516</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>495</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Teams Matches Points Ratings\n",
       "1      Australia      29  4,837     167\n",
       "2   South Africa      35  4,157     119\n",
       "3        England      36  4,205     117\n",
       "4          India      35  3,732     107\n",
       "5    New Zealand      33  3,302     100\n",
       "6    West Indies      32  2,864      90\n",
       "7     Bangladesh      12    930      78\n",
       "8       Pakistan      30  1,962      65\n",
       "9        Ireland      11    516      47\n",
       "10     Sri Lanka      11    495      45"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women_ranking('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d25bfa",
   "metadata": {},
   "source": [
    "### B) Top 10 Batting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7b16ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batswomen(link):\n",
    "    \n",
    "    # intializing various lists\n",
    "    players_w = []\n",
    "    teams_w1 = []\n",
    "    ratings_w1 = []\n",
    "    url = requests.get(link)\n",
    "    \n",
    "    # extracting data from webpage with BeautifulSoup\n",
    "    content = BeautifulSoup(url.text, 'html.parser') \n",
    "    player = content.find_all('div',class_=\"rankings-block__banner--name-large\") + content.find_all('td', class_=\"table-body__cell rankings-table__name name\", limit=9)\n",
    "    team = content.find_all('div', class_=\"rankings-block__banner--nationality\") + content.find_all('span', class_=\"table-body__logo-text\", limit=9)\n",
    "    rating = content.find_all('div', class_=\"rankings-block__banner--rating\") + content.find_all('td', class_=\"table-body__cell rating\", limit=9)\n",
    "    \n",
    "    # appending the data to various lists\n",
    "    for a in rating:\n",
    "        ratings_w1.append(a.text.strip())\n",
    "    for a in player:\n",
    "        players_w.append(a.text.strip())\n",
    "    for a in team:\n",
    "        teams_w1.append(a.text[0:5].strip())\n",
    "        \n",
    "    # imputing the data into a data frame\n",
    "    df = pd.DataFrame({'Players': players_w, 'Teams': teams_w1, 'Ratings': ratings_w1})\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "537b0ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Players</th>\n",
       "      <th>Teams</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Players Teams Ratings\n",
       "1          Alyssa Healy   AUS     785\n",
       "2           Beth Mooney   AUS     749\n",
       "3        Natalie Sciver   ENG     740\n",
       "4       Laura Wolvaardt    SA     732\n",
       "5           Meg Lanning   AUS     710\n",
       "6        Rachael Haynes   AUS     701\n",
       "7       Smriti Mandhana   IND     698\n",
       "8     Amy Satterthwaite    NZ     681\n",
       "9      Harmanpreet Kaur   IND     662\n",
       "10  Chamari Athapaththu    SL     655"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batswomen('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d6753",
   "metadata": {},
   "source": [
    "### C) Top 10 All Rounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86064282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allrounder(link):\n",
    "    \n",
    "    # intializing various lists\n",
    "    players_w2 = []\n",
    "    teams_w2 = []\n",
    "    ratings_w2 = []\n",
    "    \n",
    "    # extracting data from webpage with BeautifulSoup\n",
    "    url = requests.get(link)\n",
    "    content = BeautifulSoup(url.text, 'html.parser') \n",
    "    player = content.find_all('div',class_=\"rankings-block__banner--name-large\") + content.find_all('td', class_=\"table-body__cell rankings-table__name name\", limit=9)\n",
    "    team = content.find_all('div', class_=\"rankings-block__banner--nationality\") + content.find_all('span', class_=\"table-body__logo-text\", limit=9)\n",
    "    rating = content.find_all('div', class_=\"rankings-block__banner--rating\") + content.find_all('td', class_=\"table-body__cell rating\", limit=9)\n",
    "    \n",
    "    # appending the data to various lists\n",
    "    for a in rating:\n",
    "        ratings_w2.append(a.text.strip())\n",
    "    for a in player:\n",
    "        players_w2.append(a.text.strip())\n",
    "    for a in team:\n",
    "        teams_w2.append(a.text[0:5].strip())\n",
    "        \n",
    "    # imputing the data into a data frame\n",
    "    df = pd.DataFrame({'Players': players_w2, 'Teams': teams_w2, 'Ratings': ratings_w2})\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12ef7393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Players</th>\n",
       "      <th>Teams</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Players Teams Ratings\n",
       "1        Ellyse Perry   AUS     374\n",
       "2      Natalie Sciver   ENG     372\n",
       "3      Marizanne Kapp    SA     349\n",
       "4     Hayley Matthews    WI     339\n",
       "5         Amelia Kerr    NZ     336\n",
       "6       Deepti Sharma   IND     271\n",
       "7    Ashleigh Gardner   AUS     270\n",
       "8       Jess Jonassen   AUS     246\n",
       "9      Jhulan Goswami   IND     219\n",
       "10  Sophie Ecclestone   ENG     217"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allrounder('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150a81d",
   "metadata": {},
   "source": [
    "## 7) CNBC Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e924bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnbc_news(link):\n",
    "    \n",
    "    # intializing various lists\n",
    "    headlines = []\n",
    "    times = []\n",
    "    links = []\n",
    "    \n",
    "    # extracting data from webpage with BeautifulSoup\n",
    "    url = requests.get(link)\n",
    "    content = BeautifulSoup(url.text, 'html.parser')\n",
    "    headline = content.find_all('a', class_='LatestNews-headline')\n",
    "    time = content.find_all('time', class_=\"LatestNews-timestamp\")\n",
    "    \n",
    "    # appending the data to various lists\n",
    "    for i in headline:\n",
    "        headlines.append(i.text)\n",
    "    for i in time:\n",
    "        times.append(i.text)\n",
    "    for i in headline:\n",
    "        links.append(i['href'])\n",
    "        \n",
    "    # imputing the data into a data frame\n",
    "    df = pd.DataFrame({'Healines': headlines, 'Timestamp': times, 'Newslink': links})\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b5f340b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Healines</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Newslink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New minimum tax could hit Berkshire Hathaway a...</td>\n",
       "      <td>34 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/new-minimum-ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This market is not the dot-com crash or the fi...</td>\n",
       "      <td>46 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/cramer-this-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atlanta Fed President Bostic expects job losse...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/atlanta-fed-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>British Prime Minister to seek negotiated solu...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/british-prime-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'The Woman King' shows why the box office need...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/the-woman-king...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zelenskyy on Putin's threat of nuclear weapons...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/zelenskyy-on-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>These are the top 10 best family-friendly U.S....</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/opendoor-surve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The 3 biggest signs of 'passive aggressive' an...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/the-3-biggest-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What Kroger, Walmart, Target learned from Chin...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/what-kroger-wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How this 31-year-old got fired and re-hired at...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/this-millennia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>These stable value stocks are holding up this ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/these-stable-v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Market rout has muni bonds looking attractive....</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/market-rout-ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>These are the 6 best business books of the year</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/the-6-best-bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Meet the most powerful Hollywood player you mi...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/bryan-lourd-ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pumpkin spice latte popularity comes down to '...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/what-pumpkin-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Why Mark Cuban says he’s not ready to retire a...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/mark-cuban-say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Italy poised for hard-right leader as country ...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/italy-poised-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3 rules for a successful open relationship, ac...</td>\n",
       "      <td>24 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/three-rules-fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Biden administration awards $1.5 billion to fi...</td>\n",
       "      <td>September 24, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/biden-administ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Top 10 cities with the best pizzerias worldwid...</td>\n",
       "      <td>September 24, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/top-10-cities-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Black Girls in Trader Joe’s creator shares her...</td>\n",
       "      <td>September 24, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/easy-meals-for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Want to raise strong, resilient kids? Create '...</td>\n",
       "      <td>September 24, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/how-to-raise-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The airline race for a breakthrough climate ch...</td>\n",
       "      <td>September 24, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/how-airlines-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'Queer Eye's Karamo Brown on the morning routi...</td>\n",
       "      <td>September 24, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/queer-eyes-kar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>These 7 states have the least air pollution in...</td>\n",
       "      <td>September 24, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/vermont-new-me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>New York is now No. 1 port in a tipping point ...</td>\n",
       "      <td>September 24, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/new-york-now-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Analysts have 'high conviction' that these sto...</td>\n",
       "      <td>September 24, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/analysts-name-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Feared stock market bottom retest is now underway</td>\n",
       "      <td>September 24, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/feared-stock-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The No. 1 best city to retire isn't in Florida...</td>\n",
       "      <td>September 24, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/wallethub-top-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The perils and promise of quantum computing ar...</td>\n",
       "      <td>September 24, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/quantum-invest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Healines           Timestamp  \\\n",
       "1   New minimum tax could hit Berkshire Hathaway a...          34 Min Ago   \n",
       "2   This market is not the dot-com crash or the fi...          46 Min Ago   \n",
       "3   Atlanta Fed President Bostic expects job losse...          1 Hour Ago   \n",
       "4   British Prime Minister to seek negotiated solu...         2 Hours Ago   \n",
       "5   'The Woman King' shows why the box office need...         2 Hours Ago   \n",
       "6   Zelenskyy on Putin's threat of nuclear weapons...         3 Hours Ago   \n",
       "7   These are the top 10 best family-friendly U.S....         3 Hours Ago   \n",
       "8   The 3 biggest signs of 'passive aggressive' an...         3 Hours Ago   \n",
       "9   What Kroger, Walmart, Target learned from Chin...         4 Hours Ago   \n",
       "10  How this 31-year-old got fired and re-hired at...         4 Hours Ago   \n",
       "11  These stable value stocks are holding up this ...         4 Hours Ago   \n",
       "12  Market rout has muni bonds looking attractive....         4 Hours Ago   \n",
       "13    These are the 6 best business books of the year         5 Hours Ago   \n",
       "14  Meet the most powerful Hollywood player you mi...         5 Hours Ago   \n",
       "15  Pumpkin spice latte popularity comes down to '...         5 Hours Ago   \n",
       "16  Why Mark Cuban says he’s not ready to retire a...         5 Hours Ago   \n",
       "17  Italy poised for hard-right leader as country ...        11 Hours Ago   \n",
       "18  3 rules for a successful open relationship, ac...        24 Hours Ago   \n",
       "19  Biden administration awards $1.5 billion to fi...  September 24, 2022   \n",
       "20  Top 10 cities with the best pizzerias worldwid...  September 24, 2022   \n",
       "21  Black Girls in Trader Joe’s creator shares her...  September 24, 2022   \n",
       "22  Want to raise strong, resilient kids? Create '...  September 24, 2022   \n",
       "23  The airline race for a breakthrough climate ch...  September 24, 2022   \n",
       "24  'Queer Eye's Karamo Brown on the morning routi...  September 24, 2022   \n",
       "25  These 7 states have the least air pollution in...  September 24, 2022   \n",
       "26  New York is now No. 1 port in a tipping point ...  September 24, 2022   \n",
       "27  Analysts have 'high conviction' that these sto...  September 24, 2022   \n",
       "28  Feared stock market bottom retest is now underway  September 24, 2022   \n",
       "29  The No. 1 best city to retire isn't in Florida...  September 24, 2022   \n",
       "30  The perils and promise of quantum computing ar...  September 24, 2022   \n",
       "\n",
       "                                             Newslink  \n",
       "1   https://www.cnbc.com/2022/09/25/new-minimum-ta...  \n",
       "2   https://www.cnbc.com/2022/09/25/cramer-this-ma...  \n",
       "3   https://www.cnbc.com/2022/09/25/atlanta-fed-pr...  \n",
       "4   https://www.cnbc.com/2022/09/25/british-prime-...  \n",
       "5   https://www.cnbc.com/2022/09/25/the-woman-king...  \n",
       "6   https://www.cnbc.com/2022/09/25/zelenskyy-on-p...  \n",
       "7   https://www.cnbc.com/2022/09/25/opendoor-surve...  \n",
       "8   https://www.cnbc.com/2022/09/25/the-3-biggest-...  \n",
       "9   https://www.cnbc.com/2022/09/25/what-kroger-wa...  \n",
       "10  https://www.cnbc.com/2022/09/25/this-millennia...  \n",
       "11  https://www.cnbc.com/2022/09/25/these-stable-v...  \n",
       "12  https://www.cnbc.com/2022/09/25/market-rout-ha...  \n",
       "13  https://www.cnbc.com/2022/09/25/the-6-best-bus...  \n",
       "14  https://www.cnbc.com/2022/09/25/bryan-lourd-ho...  \n",
       "15  https://www.cnbc.com/2022/09/25/what-pumpkin-s...  \n",
       "16  https://www.cnbc.com/2022/09/25/mark-cuban-say...  \n",
       "17  https://www.cnbc.com/2022/09/25/italy-poised-f...  \n",
       "18  https://www.cnbc.com/2022/09/24/three-rules-fo...  \n",
       "19  https://www.cnbc.com/2022/09/24/biden-administ...  \n",
       "20  https://www.cnbc.com/2022/09/24/top-10-cities-...  \n",
       "21  https://www.cnbc.com/2022/09/24/easy-meals-for...  \n",
       "22  https://www.cnbc.com/2022/09/24/how-to-raise-r...  \n",
       "23  https://www.cnbc.com/2022/09/24/how-airlines-p...  \n",
       "24  https://www.cnbc.com/2022/09/24/queer-eyes-kar...  \n",
       "25  https://www.cnbc.com/2022/09/24/vermont-new-me...  \n",
       "26  https://www.cnbc.com/2022/09/24/new-york-now-n...  \n",
       "27  https://www.cnbc.com/2022/09/24/analysts-name-...  \n",
       "28  https://www.cnbc.com/2022/09/24/feared-stock-m...  \n",
       "29  https://www.cnbc.com/2022/09/24/wallethub-top-...  \n",
       "30  https://www.cnbc.com/2022/09/24/quantum-invest...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnbc_news('https://www.cnbc.com/world/?region=world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861297ea",
   "metadata": {},
   "source": [
    "## 8) Most Downloaded AI Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "213dc84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_papers(link):\n",
    "    \n",
    "    # intializing various lists\n",
    "    titles = []\n",
    "    authors = []\n",
    "    dates = []\n",
    "    links = []\n",
    "    \n",
    "    # extracting data from webpage with BeautifulSoup\n",
    "    url = requests.get(link)\n",
    "    content = BeautifulSoup(url.text, 'html.parser')\n",
    "    title = content.find_all('h2', class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\")\n",
    "    author = content.find_all('span', class_=\"sc-1w3fpd7-0 pgLAT\")\n",
    "    date = content.find_all('span', class_=\"sc-1thf9ly-2 bKddwo\")\n",
    "    link = content.find_all('a', class_=\"sc-5smygv-0 nrDZj\")\n",
    "    \n",
    "    # appending the data to various lists\n",
    "    for i in title:\n",
    "        titles.append(i.text)\n",
    "    for i in author:\n",
    "        authors.append(i.text)\n",
    "    for i in date:\n",
    "        dates.append(i.text)\n",
    "    for i in link:\n",
    "        links.append(i['href'])\n",
    "        \n",
    "    # imputing the data into a data frame\n",
    "    df = pd.DataFrame({'Paper Title': titles, 'Authors': authors, 'Date Published': dates, 'Paper Link': links})\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7038f87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Date Published</th>\n",
       "      <th>Paper Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "1                                    Reward is enough   \n",
       "2                           Making sense of raw input   \n",
       "3   Law and logic: A review from an argumentation ...   \n",
       "4              Creativity and artificial intelligence   \n",
       "5   Artificial cognition for social human–robot in...   \n",
       "6   Explanation in artificial intelligence: Insigh...   \n",
       "7                       Making sense of sensory input   \n",
       "8   Conflict-based search for optimal multi-agent ...   \n",
       "9   Between MDPs and semi-MDPs: A framework for te...   \n",
       "10  The Hanabi challenge: A new frontier for AI re...   \n",
       "11  Evaluating XAI: A comparison of rule-based and...   \n",
       "12           Argumentation in artificial intelligence   \n",
       "13  Algorithms for computing strategies in two-pla...   \n",
       "14      Multiple object tracking: A literature review   \n",
       "15  Selection of relevant features and examples in...   \n",
       "16  A survey of inverse reinforcement learning: Ch...   \n",
       "17  Explaining individual predictions when feature...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  Integrating social power into the decision-mak...   \n",
       "20  “That's (not) the output I expected!” On the r...   \n",
       "21  Explaining black-box classifiers using post-ho...   \n",
       "22  Algorithm runtime prediction: Methods & evalua...   \n",
       "23              Wrappers for feature subset selection   \n",
       "24  Commonsense visual sensemaking for autonomous ...   \n",
       "25         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Date Published  \\\n",
       "1   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "2           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "3                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "4                                 Boden, Margaret A.      August 1998   \n",
       "5     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "6                                        Miller, Tim    February 2019   \n",
       "7   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "8   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "9   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "10        Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "11  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "12               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "13       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "14             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "15                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "16                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "17      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "18  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "19    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "20                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "21  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "22  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "23                      Kohavi, Ron, John, George H.    December 1997   \n",
       "24  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "25                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                           Paper Link  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  \n",
       "25  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_papers('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd8517",
   "metadata": {},
   "source": [
    "## 9) Dineout Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b333c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dineout_det(link):\n",
    "    \n",
    "    # initializing various lists\n",
    "    names = []\n",
    "    location = []\n",
    "    rating = []\n",
    "    img_link = []\n",
    "    \n",
    "    # scrapping data from webpaage with BeautifulSoup\n",
    "    url = requests.get(link)\n",
    "    content = BeautifulSoup(url.text, 'html.parser')\n",
    "    name = content.find_all('h4', class_=\"_1jbOb\")\n",
    "    locat = content.find_all('p', class_=\"_1jbOb\")\n",
    "    rat = content.find_all('div', class_=\"kGUdK _1oTbl\")\n",
    "    img = content.find_all('img', class_=\"_1zyl5 lazy-img no-img\")\n",
    "    \n",
    "    # appending the data into various lists\n",
    "    for i in name:\n",
    "        names.append(i.text)\n",
    "    for i in locat:\n",
    "        location.append(i.text)\n",
    "    for i in rat:\n",
    "        rating.append(i.text)\n",
    "    for i in img:\n",
    "        img_link.append(i['data-src'])\n",
    "        \n",
    "    # imputing the data into a data frame\n",
    "    df = pd.DataFrame({'Name': names, 'Location': location, 'Rating': rating, 'Image Link': img_link})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2b4434d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Image Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Connaught Clubhouse Microbrewery</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38 Barracks</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Luggage Room By Sandoz</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Master Of Malts</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name                        Location Rating  \\\n",
       "0  Connaught Clubhouse Microbrewery  Connaught Place, Central Delhi    4.3   \n",
       "1                       38 Barracks  Connaught Place, Central Delhi    4.3   \n",
       "2        The Luggage Room By Sandoz  Connaught Place, Central Delhi    3.9   \n",
       "3                   Master Of Malts  Connaught Place, Central Delhi    4.1   \n",
       "\n",
       "                                          Image Link  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dineout_det('https://www.dineout.co.in')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f3cd0",
   "metadata": {},
   "source": [
    "## 10) Google Scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa9c8812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goog_scholar(link):\n",
    "    \n",
    "    # intializing various lists\n",
    "    pubs = []\n",
    "    h5_i = []\n",
    "    h5_m = []\n",
    "    ranks = []\n",
    "    \n",
    "    # extracting data from webpage with BeautifulSoup\n",
    "    url = requests.get(link)\n",
    "    content = BeautifulSoup(url.text, 'html.parser')\n",
    "    pub = content.find_all('td', class_=\"gsc_mvt_t\")\n",
    "    h5i = content.find_all('a', class_=\"gs_ibl gsc_mp_anchor\")\n",
    "    h5m = content.find_all('span', class_=\"gs_ibl gsc_mp_anchor\")\n",
    "    rank = content.find_all('td', class_=\"gsc_mvt_p\")\n",
    "    \n",
    "    # appending the data to various lists\n",
    "    for i in pub:\n",
    "        pubs.append(i.text)\n",
    "    for i in h5i:\n",
    "        h5_i.append(i.text)\n",
    "    for i in h5m:\n",
    "        h5_m.append(i.text)\n",
    "    for i in rank:\n",
    "        ranks.append(i.text)\n",
    "        \n",
    "    # imputing the data into a data frame\n",
    "    df = pd.DataFrame({'Rank': ranks,'Publication': pubs, 'h5-index': h5_i, 'h5-median': h5_m}).set_index('Rank')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6951cd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.</th>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.</th>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.</th>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.</th>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.</th>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96.</th>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.</th>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98.</th>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.</th>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.</th>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Publication h5-index h5-median\n",
       "Rank                                                                      \n",
       "1.                                               Nature      444       667\n",
       "2.                  The New England Journal of Medicine      432       780\n",
       "3.                                              Science      401       614\n",
       "4.    IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "5.                                           The Lancet      354       635\n",
       "...                                                 ...      ...       ...\n",
       "96.                        Journal of Business Research      145       233\n",
       "97.                                    Molecular Cancer      145       209\n",
       "98.                                             Sensors      145       201\n",
       "99.                               Nature Climate Change      144       228\n",
       "100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goog_scholar('https://scholar.google.com/citations?view_op=top_venues&hl=en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f52f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
